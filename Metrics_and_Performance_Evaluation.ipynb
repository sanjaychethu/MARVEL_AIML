{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Task 3: Metrics and Performance Evaluation**\n",
        "-------------------------------------------------------\n",
        "- Evaluation Metrics:\n",
        "It is used for evaluating the performance of a machine learning model\n",
        "It is necessary to obtain the accuracy on training data.\n",
        "**1. Regression Metrics:**\n",
        "   Regression is a type of Machine learning which helps in finding the relationship between independent and dependent variable.\n",
        "   The dependent variable is the variable that is being predicted, while the independent variables are the variables that are used to make the prediction.\n",
        "\n",
        "   Regression metrics are used to evaluate the performance of a regression model. They measure how well the model can predict the target variable based on the input variables.\n",
        "\n",
        "  Some of the most commonly used regression metrics include:\n",
        "\n",
        "* **Mean squared error (MSE)**: The MSE is the average of the squared differences between the predicted values and the actual values. It is a good measure of how well the model fits the data, but it can be sensitive to outliers.\n",
        "     ![mse](https://i.ibb.co/Qcvx3Gx/mse.png)\n",
        "* **Root mean squared error (RMSE)**: The RMSE is the square root of the MSE. It is a good measure of how well the model fits the data, but it is also sensitive to outliers.RMSE is almost the same as MSE, except it takes the square root of the Mean Squared Error. it overcomes any drawbacks that MAE or MSE have.\n",
        "  ![rmse](https://i.ibb.co/Tbvwppv/rmse.png)\n",
        "\n",
        "* **Mean absolute error (MAE)**: The MAE is the average of the absolute differences between the predicted values and the actual values. It is a good measure of how well the model fits the data, and it is not as sensitive to outliers as the MSE and RMSE.\n",
        " We take the absolute value of the difference between actual and predicted. This cancels out any negative values, and it is the average fundamental value of the differences between actual and predicted values.\n",
        " ![mae](https://i.ibb.co/18J0S0H/mae.png)\n",
        "\n",
        "* **Root Mean Squared Log Error**:\n",
        "  RMSLE is almost the same as RMSE except that it takes the log values of the actual and predicted values instead of using them as is. It also adds 1 to the weights if the value is 0 as the log of 0 is not defined. It is also not valid as a metric when negative values are involved.\n",
        "  ![rmlse](https://i.ibb.co/7RpP2ff/rmlse.png)\n",
        "\n",
        "* **R-squared (R^2)**: The R-squared is a measure of how well the model explains the variation in the target variable. It is a good measure of how well the model fits the data, but it can be misleading if the data is not normally distributed.\n",
        "  ![rs](https://i.ibb.co/drxD7S7/rs.png)\n",
        "\n",
        "* **Adjusted R-squared (adjusted R^2)**: The adjusted R-squared is a version of the R-squared that takes into account the number of predictors in the model. It is a good measure of how well the model fits the data, and it is not as misleading as the R-squared if the data is not normally distributed.\n",
        "  \n",
        "  ![ars](https://i.ibb.co/cc6qmbw/ars.png)\n",
        "  \n",
        "Implementing Regression Metrics:\n",
        " https://github.com/sahar-mariam/marvel-level-1-report/blob/main/regression_metrics.ipynb\n",
        "\n",
        "**2. Classification Metrics:**\n",
        "Classification metrics are used to evaluate the performance of a classification model. They measure how well the model can distinguish between different classes of data.\n",
        "\n",
        "Classification is one of the most widely used problems in machine learning with various industrial applications, from face recognition, Youtube video categorization, content moderation, medical diagnosis, to text classification.\n",
        "\n",
        "Models such as support vector machine (SVM), logistic regression, decision trees, random forest, XGboost, convolutional neural network¹, recurrent neural network are some of the most popular classification models.\n",
        "![classification metrics](https://i.ibb.co/yPn19rP/classification-metrics.png)\n",
        "\n",
        "Some of the most common metrics include:\n",
        "\n",
        "* **Confusion Matrix**:\n",
        " A confusion matrix is a table that is often used to describe the performance of a classification model on a set of test data for which the true values are known.\n",
        "\n",
        "The rows represent the actual classes the outcomes should have been. While the columns represent the predictions we have made. Using this table it is easy to see which predictions are wrong.\n",
        "\n",
        " True Positive (TP): When you predict an observation belongs to a class and it actually does belong to that class.\n",
        "\n",
        "True Negative (TN): When you predict an observation does not belong to a class and it actually does not belong to that class.\n",
        "\n",
        "False Positive (FP): When you predict an observation belongs to a class and it actually does not belong to that class.\n",
        "\n",
        "False Negative(FN): When you predict an observation does not belong to a class and it actually does belong to that class.\n",
        "\n",
        "![confusion matrix](https://i.ibb.co/QXDGr7C/confumat.png)\n",
        "\n",
        "* **Accuracy:** The accuracy of a model is the percentage of predictions that are correct. Classification Accuracy is what we usually mean, when we use the term accuracy. It is the ratio of number of correct predictions to the total number of input samples.\n",
        "\n",
        "`Accuracy score =\n",
        "No. of correct predictions/ Total no. of predictions made`\n",
        "\n",
        "![accuracy-score](https://i.ibb.co/BV1hXyJ/accuracy.png)\n",
        "\n",
        "For binary classification, we can calculate accuracy in terms of positives and negatives using the below formula:\n",
        "`Accuracy=(TP+TN)/(TP+TN+FP+FN)`\n",
        "\n",
        "* **Precision:** It is the ratio of the true positives and all the positives. It tells you that Out of all the positive classes we have predicted, how many are actually positive.\n",
        "\n",
        "![precision](https://i.ibb.co/NsH1h55/precision.png)\n",
        "\n",
        "* **Recall:**\n",
        "  It tells you that out of all the positive classes, how many we predicted correctly.\n",
        "\n",
        "Recall should be as high as possible. Note that it is also called as sensitivity.\n",
        "![recall](https://i.ibb.co/1Zxdfss/0-Xg-Go-MQLl-GGDgpz-Ya.png)\n",
        "\n",
        "* **F1 score:** It is difficult to compare two models with low precision and high recall or vice versa. If you try to increase precision, then it may decrease recall and vice versa. So it ends up in a lot of confusion.\n",
        "  So to make them comparable, we use F1-Score .F1-score helps to measure Recall and Precision at the same time.\n",
        "  ![f1](https://i.ibb.co/25PZhyw/0-tu5x-GEgs-i-Rp-J9-H.png)\n",
        "\n",
        "* **AUC-ROC Curve:**\n",
        "  The Receiver Operator Characteristic (ROC) is a probability curve that plots the TPR(True Positive Rate) against the FPR(False Positive Rate) at various threshold values and separates the ‘signal’ from the ‘noise’.\n",
        "\n",
        "![auc-roc curve](https://i.ibb.co/Jz5G0wQ/1-bpj-CSt38-Nyd-Elz-Pf6-O5-Xng.png)\n",
        "\n",
        "The Area Under the Curve (AUC) is the measure of the ability of a classifier to distinguish between classes.\n",
        "\n",
        "--------------------------------------------------------------------------------------------------------\n",
        "\n"
      ],
      "metadata": {
        "id": "L5TJ1yiekpQx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QXVcoHxSk45w"
      }
    }
  ]
}